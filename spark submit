spark-shell --master local[*] --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1 --conf spark.sql.hive.convertMetastoreParquet=false --conf spark.sql.hive.convertMetastoreParquet.binaryAsString=false --conf spark.sql.hive.convertMetastoreParquet.mergeSchema=false --conf spark.sql.hive.convertMetastoreParquet.lazyBinaryLoading=false --conf spark.sql.hive.metastorePartitionPruning=true --conf spark.sql.hive.metastorePartitionPruning.lazy=true --conf spark.sql.hive.metastorePartitionPruning.batchSize=2000 --conf spark.sql.hive.metastorePartitionPruning.threshold=2000 --conf spark.sql.shuffle.partitions=2000 --conf spark.sql.parquet.writeLegacyFormat=true --conf spark.hadoop.parquet.enable.summary-metadata=false
